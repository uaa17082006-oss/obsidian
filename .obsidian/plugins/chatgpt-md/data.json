{
  "apiKey": "",
  "openrouterApiKey": "",
  "anthropicApiKey": "",
  "geminiApiKey": "",
  "zaiApiKey": "",
  "openaiUrl": "https://api.openai.com",
  "openrouterUrl": "https://openrouter.ai",
  "ollamaUrl": "http://localhost:11434",
  "lmstudioUrl": "http://127.0.0.1:11434",
  "anthropicUrl": "https://api.anthropic.com",
  "geminiUrl": "https://generativelanguage.googleapis.com",
  "zaiUrl": "https://api.z.ai",
  "chatFolder": "ChatGPT_MD/chats",
  "chatTemplateFolder": "ChatGPT_MD/templates",
  "agentFolder": "ChatGPT_MD/agents",
  "stream": true,
  "generateAtCursor": false,
  "autoInferTitle": false,
  "enableToolCalling": false,
  "toolEnabledModels": "# OpenAI (36 patterns)\ncodex-mini-latest\ngpt-3.5-turbo\ngpt-3.5-turbo-0125\ngpt-3.5-turbo-1106\ngpt-4\ngpt-4-0125-preview\ngpt-4-0613\ngpt-4-1106-preview\ngpt-4-turbo\ngpt-4-turbo-preview\ngpt-4.1\ngpt-4.1-mini\ngpt-4.1-nano\ngpt-4o\ngpt-4o-mini\ngpt-5\ngpt-5-chat-latest\ngpt-5-codex\ngpt-5-mini\ngpt-5-nano\ngpt-5-pro\ngpt-5.1\ngpt-5.1-chat-latest\ngpt-5.1-codex\ngpt-5.1-codex-max\ngpt-5.1-codex-mini\ngpt-5.2\ngpt-5.2-chat-latest\ngpt-5.2-codex\ngpt-5.2-pro\no1\no1-pro\no3\no3-mini\no3-pro\no4-mini\n\n# Anthropic (9 patterns)\nclaude-3-5-haiku\nclaude-3-7-sonnet\nclaude-3-haiku\nclaude-haiku-4-5\nclaude-opus-4\nclaude-opus-4-1\nclaude-opus-4-5\nclaude-sonnet-4\nclaude-sonnet-4-5\n\n# Gemini (7 patterns)\ngemini-2.5-flash\ngemini-2.5-flash-lite-preview-09-2025\ngemini-2.5-flash-preview-09-2025\ngemini-3-flash-preview\ngemini-flash-latest\ngemini-flash-lite-latest\ngemini-robotics-er-1.5-preview\n\n# OpenRouter (109 patterns)\nai21/jamba-mini-1.7\nalibaba/tongyi-deepresearch-30b-a3b\nallenai/olmo-3.1-32b-instruct\namazon/nova-lite-v1\namazon/nova-pro-v1\nanthropic/claude-3-haiku\nanthropic/claude-3.5-haiku\narcee-ai/trinity-large-preview:free\nbytedance-seed/seed-1.6\nbytedance-seed/seed-1.6-flash\ncohere/command-r-08-2024\ncohere/command-r-plus-08-2024\ndeepcogito/cogito-v2-preview-llama-109b-moe\ndeepcogito/cogito-v2-preview-llama-405b\ndeepcogito/cogito-v2-preview-llama-70b\ndeepseek/deepseek-chat\ndeepseek/deepseek-chat-v3-0324\ndeepseek/deepseek-chat-v3.1\ndeepseek/deepseek-r1\ndeepseek/deepseek-r1-0528\ndeepseek/deepseek-v3.1-terminus\ndeepseek/deepseek-v3.1-terminus:exacto\ndeepseek/deepseek-v3.2\ndeepseek/deepseek-v3.2-exp\ngoogle/gemini-2.0-flash-lite-001\ninception/mercury\ninception/mercury-coder\nkwaipilot/kat-coder-pro\nmeta-llama/llama-3.1-405b-instruct\nmeta-llama/llama-3.1-70b-instruct\nmeta-llama/llama-4-maverick\nmeta-llama/llama-4-scout\nminimax/minimax-m1\nminimax/minimax-m2\nminimax/minimax-m2.1\nmistralai/codestral-2508\nmistralai/devstral-2512\nmistralai/devstral-small\nmistralai/ministral-14b-2512\nmistralai/ministral-3b\nmistralai/ministral-3b-2512\nmistralai/ministral-8b\nmistralai/ministral-8b-2512\nmistralai/mistral-large-2512\nmistralai/mistral-nemo\nmistralai/mistral-saba\nmistralai/mistral-small-24b-instruct-2501\nmistralai/mistral-small-creative\nmistralai/mistral-tiny\nmistralai/pixtral-12b\nmistralai/voxtral-small-24b-2507\nmoonshotai/kimi-k2-0905\nmoonshotai/kimi-k2-0905:exacto\nnex-agi/deepseek-v3.1-nex-n1\nnvidia/llama-3.1-nemotron-70b-instruct\nnvidia/llama-3.3-nemotron-super-49b-v1.5\nnvidia/nemotron-3-nano-30b-a3b\nnvidia/nemotron-3-nano-30b-a3b:free\nnvidia/nemotron-nano-12b-v2-vl:free\nnvidia/nemotron-nano-9b-v2\nnvidia/nemotron-nano-9b-v2:free\nopenai/gpt-3.5-turbo\nopenai/gpt-3.5-turbo-0613\nopenai/gpt-3.5-turbo-16k\nopenai/gpt-4.1-mini\nopenai/gpt-4.1-nano\nopenai/gpt-4o\nopenai/gpt-4o-mini\nopenai/gpt-5-nano\nopenai/gpt-oss-120b\nopenai/gpt-oss-120b:exacto\nopenai/gpt-oss-20b\nopenai/gpt-oss-safeguard-20b\nopenrouter/auto\nprime-intellect/intellect-3\nqwen/qwen-2.5-72b-instruct\nqwen/qwen-2.5-7b-instruct\nqwen/qwen-max\nqwen/qwen-plus\nqwen/qwen-vl-max\nqwen/qwen3-14b\nqwen/qwen3-235b-a22b\nqwen/qwen3-235b-a22b-thinking-2507\nqwen/qwen3-30b-a3b\nqwen/qwen3-30b-a3b-instruct-2507\nqwen/qwen3-30b-a3b-thinking-2507\nqwen/qwen3-32b\nqwen/qwen3-8b\nqwen/qwen3-coder\nqwen/qwen3-coder-30b-a3b-instruct\nqwen/qwen3-coder-flash\nqwen/qwen3-coder:exacto\nqwen/qwen3-next-80b-a3b-instruct\nqwen/qwen3-next-80b-a3b-thinking\nqwen/qwen3-vl-235b-a22b-instruct\nqwen/qwen3-vl-30b-a3b-instruct\nqwen/qwen3-vl-30b-a3b-thinking\nqwen/qwen3-vl-8b-instruct\nqwen/qwq-32b\nstepfun-ai/step3\ntngtech/deepseek-r1t2-chimera\ntngtech/tng-r1t-chimera\ntngtech/tng-r1t-chimera:free\nupstage/solar-pro-3:free\nx-ai/grok-3-mini\nx-ai/grok-3-mini-beta\nx-ai/grok-4-fast\nx-ai/grok-4.1-fast\nx-ai/grok-code-fast-1\nxiaomi/mimo-v2-flash\nz-ai/glm-4-32b\nz-ai/glm-4.5\nz-ai/glm-4.5-air\nz-ai/glm-4.5-air:free\nz-ai/glm-4.5v\nz-ai/glm-4.6\nz-ai/glm-4.6:exacto\nz-ai/glm-4.6v\nz-ai/glm-4.7\nz-ai/glm-4.7-flash\n\n# Z.AI (GLM Models)\nglm-4\nglm-4.7\nglm-4.7-flash",
  "debugMode": true,
  "pluginSystemMessage": "You're chatting with a user in Obsidian, a knowledge management system where they organize notes in interconnected Markdown files. This conversation appears as a chat within their active document.\n\nBe helpful and concise. Use proper Markdown: ```language for code blocks, `inline` for code/filenames. Support [[Internal Links]] and [external links](url). Consider this chat is part of their personal knowledge base.\n\nWhen appropriate, end with an open question to keep the conversation helpful and make contextual offers based on their last message.",
  "webSearchProvider": "brave",
  "webSearchApiKey": "",
  "webSearchApiUrl": "",
  "maxWebSearchResults": 5,
  "dateFormat": "YYYYMMDDhhmmss",
  "headingLevel": 3,
  "inferTitleLanguage": "Russian",
  "defaultChatFrontmatter": "",
  "openaiDefaultModel": "openai@gpt-4.1-mini",
  "openaiDefaultTemperature": 0.7,
  "openaiDefaultTopP": 1,
  "openaiDefaultMaxTokens": 400,
  "openaiDefaultPresencePenalty": 0,
  "openaiDefaultFrequencyPenalty": 0,
  "anthropicDefaultModel": "anthropic@claude-sonnet-4-20250514",
  "anthropicDefaultTemperature": 0.7,
  "anthropicDefaultMaxTokens": 400,
  "geminiDefaultModel": "gemini@",
  "geminiDefaultTemperature": 0.7,
  "geminiDefaultTopP": 1,
  "geminiDefaultMaxTokens": 400,
  "openrouterDefaultModel": "openrouter@openai/gpt-4.1-mini",
  "openrouterDefaultTemperature": 0.7,
  "openrouterDefaultTopP": 1,
  "openrouterDefaultMaxTokens": 400,
  "openrouterDefaultPresencePenalty": 0.5,
  "openrouterDefaultFrequencyPenalty": 0.5,
  "ollamaDefaultTemperature": "0.5",
  "ollamaDefaultTopP": 1,
  "lmstudioDefaultTemperature": "0.5",
  "lmstudioDefaultTopP": 1,
  "lmstudioDefaultPresencePenalty": 0,
  "lmstudioDefaultFrequencyPenalty": 0,
  "zaiDefaultModel": "zai@glm-4.7",
  "zaiDefaultTemperature": 0.7,
  "zaiDefaultMaxTokens": 400
}